{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using LangChain and ChatGPT to query Google Calendar.\n\nOr, how to use LangChain and ChatGPT as a personal assistant.\n\nGoogle Calendar guides my workday, and recently I've begun using it to apply [Timeboxing](https://www.mindtools.com/a9bt6jr/timeboxing) in my day-to-day life.\n\nNaturally, I was curious how I can feed that data to ChatGPT as context to be able to utilise Natural Language queries, over my Google Calendar to get daily summaries, insights and reminders. Turns out you can do this + a lot more!\n\n**Libraries used**\n\n* LangChain - Framework for LLM\n* OpenAI API - Create embeddings + utilise LLM Model\n* ChromaDB - Vector store\n\nIn order to interact with Google Calendar API, we need to follow the instructions [here](https://developers.google.com/workspace/guides/create-credentials) and create OAuth application and download `credentials.json`.\n\n**⚠️ Disclaimer**\n\n* Running Langchain with your own OpenAI API key, will consume credits, please be careful and monitor costs.\n* This is my 2nd project with LangChain and LLMs I might not have the nomenclature down correctly, if there are inconsistencies let me know and I will do my best to update.\n* You can't run the Notebook on Kaggle, as it creates a server for Google OAuth to callback and authenticate.","metadata":{}},{"cell_type":"markdown","source":"Once the credentials are downloaded, next step is to load that data in, for this I'll be using a slightly modified version of the Llama Hub [GoogleCalendarReader](https://llamahub.ai/l/google_calendar) code can be found [here](https://github.com/emptycrown/llama-hub/tree/main/loader_hub/google_calendar).","metadata":{}},{"cell_type":"code","source":"\"\"\"\nGoogle Calendar reader.\n\"\"\"\n\nimport datetime\nimport os\nfrom typing import Any, List, Optional, Union\n\nfrom llama_index.readers.base import BaseReader\nfrom llama_index.readers.schema.base import Document\n\nSCOPES = [\"https://www.googleapis.com/auth/calendar.readonly\"]\n\n# Copyright 2018 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nclass GoogleCalendarReader(BaseReader):\n    \"\"\"Google Calendar reader.\n\n    Reads events from Google Calendar\n\n    \"\"\"\n\n    def load_data(\n        self,\n        number_of_results: Optional[int] = 100,\n        start_date: Optional[Union[str, datetime.date]] = None,\n    ) -> List[Document]:\n\n        \"\"\"Load data from user's calendar.\n\n        Args:\n            number_of_results (Optional[int]): the number of events to return. Defaults to 100.\n            start_date (Optional[Union[str, datetime.date]]): the start date to return events from. Defaults to today.\n        \"\"\"\n\n        from googleapiclient.discovery import build\n\n        credentials = self._get_credentials()\n        service = build(\"calendar\", \"v3\", credentials=credentials)\n\n        if start_date is None:\n            start_date = datetime.date.today()\n        elif isinstance(start_date, str):\n            start_date = datetime.date.fromisoformat(start_date)\n\n        start_datetime = datetime.datetime.combine(start_date, datetime.time.min)\n        start_datetime_utc = start_datetime.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n\n        events_result = (\n            service.events()\n            .list(\n                calendarId=\"primary\",\n                timeMin=start_datetime_utc,\n                maxResults=number_of_results,\n                singleEvents=True,\n                orderBy=\"startTime\",\n            )\n            .execute()\n        )\n\n        events = events_result.get(\"items\", [])\n\n        if not events:\n            return []\n\n        results = []\n        for event in events:\n            if \"dateTime\" in event[\"start\"]:\n                start_time = event[\"start\"][\"dateTime\"]\n            else:\n                start_time = event[\"start\"][\"date\"]\n\n            if \"dateTime\" in event[\"end\"]:\n                end_time = event[\"end\"][\"dateTime\"]\n            else:\n                end_time = event[\"end\"][\"date\"]\n\n            event_string = f\"Status: {event['status']}, \"\n            event_string += f\"Summary: {event['summary']}, \"\n            event_string += f\"Start time: {start_time}, \"\n            event_string += f\"End time: {end_time}, \"\n\n            organizer = event.get(\"organizer\", {})\n            display_name = organizer.get(\"displayName\", \"N/A\")\n            email = organizer.get(\"email\", \"N/A\")\n            if display_name != \"N/A\":\n                event_string += f\"Organizer: {display_name} ({email})\"\n            else:\n                event_string += f\"Organizer: {email}\"\n\n            results.append(Document(event_string))\n\n        return results\n\n    def _get_credentials(self) -> Any:\n        \"\"\"Get valid user credentials from storage.\n\n        The file token.json stores the user's access and refresh tokens, and is\n        created automatically when the authorization flow completes for the first\n        time.\n\n        Returns:\n            Credentials, the obtained credential.\n        \"\"\"\n        from google.auth.transport.requests import Request\n        from google.oauth2.credentials import Credentials\n        from google_auth_oauthlib.flow import InstalledAppFlow\n\n        creds = None\n        if os.path.exists(\"token.json\"):\n            creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n        # If there are no (valid) credentials available, let the user log in.\n        if not creds or not creds.valid:\n            if creds and creds.expired and creds.refresh_token:\n                creds.refresh(Request())\n            else:\n                flow = InstalledAppFlow.from_client_secrets_file(\n                    \"credentials.json\", SCOPES\n                )\n                creds = flow.run_local_server(port=3030)\n            # Save the credentials for the next run\n            with open(\"token.json\", \"w\") as token:\n                token.write(creds.to_json())\n\n        return creds","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-05-09T16:05:14.053663Z","start_time":"2023-05-09T16:05:14.048918Z"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add OPENAI_API_KEY\n\nimport dotenv\ndotenv.load_dotenv()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-05-09T16:05:14.060213Z","start_time":"2023-05-09T16:05:14.051946Z"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nThe following makes a request to Google Calendar API with the OAuth token\nand retrieves number_of_results from the specified date.\n'''\n\nfrom GoogleCalendarReader import GoogleCalendarReader\nfrom datetime import date\n\nloader = GoogleCalendarReader()\ndocuments = loader.load_data(start_date=date.today(), number_of_results=50)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-05-09T16:05:14.429655Z","start_time":"2023-05-09T16:05:14.056280Z"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LangChain has a specific schema for the documents, which we need to convert to. Luckily retrievers from LlamaHub work with Langchain, we just need to call `.to_langchain_format()` over the retrieved documents.","metadata":{}},{"cell_type":"code","source":"from typing import List\nfrom langchain.docstore.document import Document as LCDocument\n\nformatted_documents: List[LCDocument] = [doc.to_langchain_format() for doc in documents]","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-05-09T16:05:14.436730Z","start_time":"2023-05-09T16:05:14.431201Z"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have normalised data, we just need to put it together in a ConversationalRetrievalChain. Langchain provides various ways of interacting with LLMs from simple: [VectorstoreIndexCreatora](https://python.langchain.com/en/latest/modules/indexes/getting_started.html), to more complex \"chains\" which rely on Prompt engineering to get the most out of the LLM.\n\nTo interact with Google Calendar and ask any follow-up questions, going to use ConversationalRetrievalChain, which preserves the chat history, and feeds it back to the LLM, when asking my question.","metadata":{}},{"cell_type":"code","source":"from langchain import OpenAI\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.memory import ConversationBufferMemory\n\n'''\nOpenAIEmbeddings uses text-embedding-ada-002\n'''\n\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocuments = text_splitter.split_documents(formatted_documents)\nembeddings = OpenAIEmbeddings()\nvector_store = Chroma.from_documents(documents, embeddings)\nmemory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n\nqa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=2, model_name=\"gpt-4\"), vector_store.as_retriever(), memory=memory)\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-05-09T16:05:25.948598Z","start_time":"2023-05-09T16:05:25.421678Z"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have everything set-up and are ready to start querying.","metadata":{}},{"cell_type":"code","source":"from IPython.display import Markdown\n\nchat_history = []\nquery = \"Create a summary for what am I doing on the day: 2023-05-09\"\nresult = qa({\"question\": query})","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-05-09T16:05:44.481554Z","start_time":"2023-05-09T16:05:27.999303Z"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On May 9, 2023, you have the following activities:\n\n* Deep Work from 10:00 AM to 12:30 PM\n* Work Lunch from 1:00 PM to 2:00 PM\n* Interview from 2:30 PM to 3:30 PM\n* Standup Meeting - Daily from 3:30 PM to 4:00 PM","metadata":{}},{"cell_type":"markdown","source":"Some other ideas: \n\n* Find suitable timeslots on the calendar: \"When is the best time to schedule a one hour workout\"\n* Integrate multiple calendars, find what time is the best to schedule events. ","metadata":{}},{"cell_type":"markdown","source":"Thank you for reading, and hopefully this is a usefule showcase on how to give ChatGPT context over your calendar. ","metadata":{}}]}